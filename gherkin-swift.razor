// - Mark: Generated Code
@using Berp;
@helper CallProduction(ProductionRule production)
{
    switch(production.Type)
    {
        case ProductionRuleType.Start:
                @:startRule(ctx: ctx, type: RuleType.@production.RuleName)
            break;
        case ProductionRuleType.End:
                @:endRule(ctx: ctx, type: RuleType.@production.RuleName)
            break;
        case ProductionRuleType.Process:
                @:build(ctx: ctx, token: token)
            break;
    }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
            let stateComment = "State: @state.Id - @Raw(state.Comment)"
            token.detach()
            var expectedTokens: [String] = {"@Raw(string.Join("\", \"", expectedTokens))"}
            var error: ParserError = token.isEOF ? 
                ParserError.unexpectedEOFException(token: token, expected: expectedTokens, comment: stateComment) :
                ParserError.unexpectedTokenError(token: token, expected: expectedTokens, comment: stateComment)
            if stopAtFirstError {
                throw error
            }
            
            addError(ctx: ctx, error: error)

            return @state.Id
</text>}
@helper MatchToken(TokenType tokenType)
{<text>match@(tokenType)(ctx: ctx, token: token)</text>}

    public class @Model.ParserClassName<T> {
        private var astBuilder: IAstBuilder
        
        enum ParserError: Error {
            case unexpectedTokenError(token: Token, expected [String], comment: String)
            case unexpectedEOFError(token: Token, expected [String], comment: String)
            case compositeParserError(errors: [ParserError])
            case invalidOperationException(message: String)
        }
        
        struct ParserContext {
            public var tokenScanner: ITokenScanner
            public var tokenMatcher: ITokenMatcher
            public var tokenQueue: Queue<Token>
            public var errors: [ParserError]
        }

        struct Queue<T> {
            var list = [T]()

            var count: Int { 
                get {
                    return list.count
                }
            }
            mutating func enqueue(item: T) {
                list.append(item)
            }

            mutating func dequeue() -> T? {
                if !list.isEmpty {
                    return list.removeFirst()
                } else {
                    return nil
                }
            }
        }

        public convenience init() {
            self.init(AstBuilder<T>())
        }

        public init(astBuilder: IAstBuilder) {
            self.astBuilder = astBuilder
        }

        public var stopAtFirstError: Bool

        public func parse(tokenScanner: ITokenScanner) -> T {
            return parse(tokenScanner, TokenMatcher())
        }

        public func parse(tokenScanner: ITokenScanner, tokenMatcher: ITokenMatcher) -> T {
            tokenMatcher.reset()
            astBuilder.reset()
            var context = ParserContext(
                tokenScanner: tokenScanner,
                tokenMatcher: tokenMatcher,
                tokenQueue: Queue<Token>(),
                errors: [ParserError]())

            startRule(ctx: context, type: RuleType.@Model.RuleSet.StartRule.Name)
            var tate = 0
            var token: Token
            repeat {
                token = readToken(ctx: context)
                state = matchToken(state: state, token, ctx: context)
            } while !token.isEOF

            endRule(ctx: context, type: RuleType.@Model.RuleSet.StartRule.Name)

            if ctx.errors.count > 0 {
                throw ParserError.compositeParserException(errors: ctx.errors))
            }

            return getResult(ctx: context)
        }

        private func addError(ctx: ParserContext, error: ParserException) {
            if ctx.errors.contains($0.message == error.message)) { return }
                
            ctx.errors.add(error: error)
            if ctx.errors.count > 10 {
                throw ParserError.compositeParserException(errors: ctx.errors)
            }
        }

        private func handleAstError(ctx: ParserContext, action: @@escaping () -> Void) {
            handleExternalError(ctx: ctx) { () -> Bool in 
                action()
                return true 
            }
        }

        private func handleExternalError<T>(ctx: ParserContext, defaultValue: T = T(), action: @@escaping () -> T) -> T {
            if stopAtFirstError {
                return action()
            }

            do {
                return action()
            } catch ParserError.compositeParserError {
                for e in error.errors {
                    addError(ctx: ctx, error: e)
                }
            } catch ParserError
            {
                addError(ctx: ctx, error: error);
            }
            return defaultValue;
        }

        func build(ctx: ParserContext, token: Token) {
            handleAstError(ctx: ctx) {
                self.astBuilder.build(token: token)
            }
        }

        func startRule(ctx: ParserContext, type: RuleType) {
            handleAstError(ctx: ctx) {
                self.astBuilder.startRule(type: ruleType)
            }
        }

        func endRule(ctx: ParserContext, type: RuleType) {
            handleAstError(ctx: ctx) {
                self.astBuilder.endRule(ruleType)
            }
        }

        func getResult(ctx: ParserContext) -> T {
            return self.astBuilder.getResult()
        }

        func readToken(ctx: ParserContext) -> Token {
            return ctx.tokenQueue.count > 0 ? ctx.tokenQueue.dequeue() : ctx.tokenScanner.read()
        }

        @foreach(var rule in Model.RuleSet.TokenRules)
        {<text>
        func match@(rule.Name.Replace("#", ""))(ctx: ParserContext, token: Token) -> Bool {
            @if (rule.Name != "#EOF")
            {
            @:if token.isEOF  { return false }
            }
            return handleExternalError(ctx: ctx, defaultValue: false) {
                ctx.tokenMatcher.match@(rule.Name.Replace("#", ""))(token: token)
            } 
        }</text>
        }

        public func matchToken(state: Int, token: Token, ctx: ParserContext) -> Int {
            var newState: Int
            switch state {
            @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
            {
                @:case @state.Id:
                    @:newState = matchTokenAt@(state.Id)(token: token, ctx: ctx)
                    @:break
            }
                default:
                    throw ParserError.invalidOperationException(message: "Unknown state: \(state)")
            }
            return newState
        }

    @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
    {
        <text>
        // @Raw(state.Comment)
        func matchTokenAt@(state.Id)(token: Token, ctx: ParserContext) -> Int
        {
            @foreach(var transition in state.Transitions)
            {
            @:if (@MatchToken(transition.TokenType))
            @:{
                if (transition.LookAheadHint != null)
                {
                @:if LookAhead@(transition.LookAheadHint.Id)(ctx: ctx, token: token)
                @:{
                }
                foreach(var production in transition.Productions)
                {
                    @CallProduction(production)
                }
                @:return @transition.TargetState;
                if (transition.LookAheadHint != null)
                {
                @:}
                }
            @:}
            }
            @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
        }
        </text>
    }

    @foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
    {
        <text>
        func lookAhead@(lookAheadHint.Id)(ctx: ParserContext, currentToken: Token) -> Bool
        {
            currentToken.detach()
            var token: Token
            var queue = Queue<Token>()
            var match = false
            repeat {
                token = readToken(ctx: ctx)
                token.detach()
                queue.enqueue(item: token)

                if false
                @foreach(var tokenType in lookAheadHint.ExpectedTokens)
                {
                    @:|| @MatchToken(tokenType)
                }
                {
                    match = true
                    break
                }
           } while false
            @foreach(var tokenType in lookAheadHint.Skip)
            {
                @:|| @MatchToken(tokenType)
            }
            for t in queue {
                ctx.tokenQueue.enqueue(item: t)
            }
            return match
        }
        </text>
    }
    }

    public protocol IAstBuilder 
    {
        associatedtype T
        func build(token: Token)
        func startRule(type: RuleType)
        func endRule(type: RuleType)
        func getResult() -> T
        func reset()
    }

    public protocol ITokenScanner
    {
        func read() -> Token
    }

    public protocol ITokenMatcher
    {
        @foreach(var rule in Model.RuleSet.TokenRules)
        {
        @:func match@(rule.Name.Replace("#", ""))(token: Token) -> Bool
        }
        func reset()
    }
